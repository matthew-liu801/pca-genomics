{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import msprime\n",
    "from scipy import linalg, stats\n",
    "import utils\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import pysam\n",
    "import pandas as pd\n",
    "from typing import Callable\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate data and clean real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean old data\n",
    "\n",
    "vcf_path = \"raw_data/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.vcf.gz\"\n",
    "vcf_file = pysam.VariantFile(vcf_path)\n",
    "\n",
    "records = [record for record in vcf_file.fetch()]\n",
    "\n",
    "\n",
    "# Filter data\n",
    "\n",
    "#16 minutes: 154k observations\n",
    "filtered_by_maf = utils.filter_maf(records)\n",
    "#2 minutes: no change\n",
    "filtered_by_missingness = utils.filter_missingness(filtered_by_maf)\n",
    "#13 seconds: no change\n",
    "filtered_by_quality = utils.filter_quality(filtered_by_missingness)\n",
    "\n",
    "records = filtered_by_quality\n",
    "\n",
    "# Getting the number of samples and SNPs\n",
    "num_samples = len(vcf_file.header.samples)\n",
    "num_snps = len(records)\n",
    "\n",
    "# Create an empty genotype matrix\n",
    "G = np.empty((num_samples, num_snps), dtype=int)\n",
    "\n",
    "# Fill the matrix\n",
    "for j, record in enumerate(records):\n",
    "    for i, sample in enumerate(vcf_file.header.samples):\n",
    "        genotype = record.samples[sample].allele_indices\n",
    "        # Biallelic SNPs\n",
    "        if genotype == (0, 0):\n",
    "            G[i][j] = 0\n",
    "        elif genotype in [(0, 1), (1, 0)]:\n",
    "            G[i][j] = 1\n",
    "        else:\n",
    "            G[i][j] = 2\n",
    "\n",
    "\n",
    "U, S, Vt = np.linalg.svd(G, full_matrices = False)\n",
    "\n",
    "np.savez_compressed(\"../processed_data/real/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes)_SVD.npz\", U = U, S = S, Vt = Vt)\n",
    "np.savez_compressed(\"../processed_data/real/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.npz\", G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We simulate data of various sizes, sequence lengths, and sparsities\n",
    "sample_sizes = [50, 200, 1000, 10000]\n",
    "sequence_lengths = [10**x for x in range(4, 8)]\n",
    "mutation_rates = [1e-4, 1e-6, 1e-8] #lower mutation rate = sparser\n",
    "recombination_rate = 1e-7\n",
    "\n",
    "G_simulated = {}\n",
    "\n",
    "for n in sample_sizes:\n",
    "    for length in sequence_lengths:\n",
    "        for mut_rate in mutation_rates:\n",
    "            G = utils.simulate_diploid_genotypes(n, length, mut_rate, recombination_rate)\n",
    "            if G.shape[1] >= 10:\n",
    "                G_simulated[(n, length, mut_rate)] = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save simulated data\n",
    "data_dir = \"../processed_data/simulated\"\n",
    "for (params, G) in G_simulated.items():\n",
    "    file_name = f\"{params[0]}_{params[1]}_{params[2]}.genotypes.npz\"\n",
    "    np.savez_compressed(f\"{data_dir}/{file_name}\", G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real data from 1000 genomes project\n",
    "G = np.load(\"../processed_data/real/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes.npz\")['arr_0']\n",
    "svd_data = np.load(\"../processed_data/real/ALL.chr21.phase3_shapeit2_mvncall_integrated_v5b.20130502.genotypes)_SVD.npz\")\n",
    "\n",
    "U, S, Vt = svd_data[\"U\"], svd_data[\"S\"], svd_data[\"Vt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulated data\n",
    "\n",
    "sample_sizes = [50, 200, 1000, 10000]\n",
    "sequence_lengths = [10**x for x in range(4, 8)] \n",
    "mutation_rates = [1e-4, 1e-6, 1e-8] #lower mutation rate = sparser\n",
    "recombination_rate = 1e-7\n",
    "\n",
    "G_simulated = {}\n",
    "\n",
    "simulated_dir = \"../processed_data/simulated/\"\n",
    "for n in sample_sizes:\n",
    "    for length in sequence_lengths:\n",
    "        for mut_rate in mutation_rates:\n",
    "            file_name = f\"{n}_{length}_{mut_rate}.genotypes.npz\"\n",
    "            file_dir = simulated_dir + file_name \n",
    "            try:\n",
    "                G = np.load(file_dir)[\"arr_0\"]\n",
    "                G_simulated[(n, length, mut_rate)] = G\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sparsity statistics for G\n",
    "utils.count_genotypes(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sparsity statistics\n",
    "G_simulated_props = {key: utils.count_genotypes(G_simulated[key]) for key in G_simulated.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataframe\n",
    "df_keys = [{'Parameters': key, 'Shape of G': G_simulated[key].shape,\n",
    "         'Proportion Zeros': value[0], 'Proportion Ones': value[1], 'Proportion Twos': value[2]}\n",
    "        for key, value in G_simulated_props.items()]\n",
    "\n",
    "G_df = pd.DataFrame(df_keys)\n",
    "\n",
    "# Write to LaTeX\n",
    "with open('../figures/sim_data_table.txt', 'w') as f:\n",
    "    f.write(G_df.to_latex(index=False,\n",
    "                          bold_rows=False,\n",
    "                          float_format=\"%.2f\"))\n",
    "\n",
    "G_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Darnell et al: ARSVD\n",
    "\n",
    "Paper: https://www.jmlr.org/papers/volume18/15-143/15-143.pdf \n",
    "\n",
    "Implementation: https://github.com/gdarnell/arsvd/blob/master/dimension_reduction.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsvd(X, dstar, power_iters=2, delta=10):\n",
    "\t\"\"\" Perform rsvd algorithm on input matrix.\n",
    "\t\tMethod must be supplied dstar.\n",
    "\t\tReturns truncated svd (U,S,V).\n",
    "\tParameters\n",
    "\t----------\n",
    "\tX : int matrix\n",
    "    \tMatrix of n x m integers, where m <= n. If n < m,\n",
    "    \tmatrix will be transposed to enforce m <= n.\n",
    "   \tdstar : int\n",
    "   \t\tThe latent (underlying) matrix rank that will be\n",
    "   \t\tused to truncate the larger dimension (m).\n",
    "   \tpower_iters : int\n",
    "   \t\tdefault: 2\n",
    "   \t\tNumber of power iterations used (random matrix multiplications)\n",
    "   \tdelta : int\n",
    "   \t\tdefault: 10\n",
    "   \t\toversampling parameter (to improve numerical stability)\n",
    "    Returns\n",
    "\t-------\n",
    "\tint matrix\n",
    "    \tMatrix of left singular vectors.\n",
    "    int matrix\n",
    "    \tMatrix of singular values.\n",
    "    int matrix\n",
    "    \tMatrix of right singular vectors.\n",
    "    \"\"\"\n",
    "\ttranspose = False \n",
    "\tif X.shape[0] < X.shape[1]:\n",
    "\t\tX = X.T \n",
    "\t\ttranspose = True \n",
    "\n",
    "\tif power_iters < 1:\n",
    "\t\tpower_iters = 1\n",
    "\n",
    "\t# follows manuscript notation as closely as possible\n",
    "\tP = np.random.randn(X.shape[0],dstar+delta)\t\n",
    "\tfor i in range(power_iters):\n",
    "\t\tP = np.dot(X.T,P)\n",
    "\t\tP = np.dot(X,P)\n",
    "\tQ,R = np.linalg.qr(P)\n",
    "\tB = np.dot(Q.T,X)\n",
    "\tU,S,V = linalg.svd(B)\n",
    "\tU = np.dot(Q, U)\n",
    "\n",
    "\t# Remove extra dimensionality incurred by delta\n",
    "\tU = U[:, 0:dstar]\n",
    "\tS = S[0:dstar]\n",
    "\n",
    "\treturn (V.T, S, U.T) if transpose else (U, S, V)\n",
    "\n",
    "\n",
    "def stabilityMeasure(X, d_max, B=5, power_iters=2):\n",
    "\t\"\"\" Calculate stability of \n",
    "\tParameters\n",
    "\t----------\n",
    "\tX : int matrix\n",
    "\t\tinput matrix to determine rank of\n",
    "\td_max : int\n",
    "\t\tupper bound rank to estimate\n",
    "\tB : int\n",
    "\t\tdefault: 5\n",
    "\t\tnumber of projections to correlate\n",
    "\tpower_iters : int\n",
    "\t\tdefault: 2\n",
    "   \t\tNumber of power iterations used (random matrix multiplications)\n",
    "\tReturns\n",
    "\t-------\n",
    "\tint\n",
    "\t\tLatent (lower-dimensional) matrix rank\n",
    "\t\"\"\"\n",
    "\tsingular_basis = np.zeros((B,X.shape[0],d_max))\n",
    "\t# calculate singular basis under multiple projections\n",
    "\tfor i in range(B):\n",
    "\t\tU = rsvd(X,d_max)[0]\n",
    "\t\tsingular_basis[i,:,:] = U[:,0:d_max]\n",
    "\n",
    "\t# calculate score for each singular vector\n",
    "\tstability_vec = np.zeros((d_max))\n",
    "\tfor k in range(d_max):\n",
    "\t\tstability = 0\n",
    "\t\tfor i in range(0,B-1):\n",
    "\t\t\tfor j in range(i+1,B):\n",
    "\t\t\t\tcorr = stats.spearmanr(singular_basis[i,:,k],singular_basis[j,:,k])[0]\n",
    "\t\t\t\tstability = stability + abs(corr)\n",
    "\t\tN = B*(B-1)/2\n",
    "\t\tstability = stability/N\n",
    "\t\tstability_vec[k] = stability\n",
    "\n",
    "\t# wilcoxon rank-sum test p-values\n",
    "\tp_vals = np.zeros(d_max-2)\n",
    "\tfor k in range(2,d_max):\n",
    "\t\tp_vals[k-2] = stats.ranksums(stability_vec[0:k-1],stability_vec[k-1:d_max])[1]\n",
    "\n",
    "\tdstar = np.argmin(p_vals)\n",
    "\t\n",
    "\treturn dstar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saibaba et al: GSVD\n",
    "\n",
    "Paper: https://www.osti.gov/servlets/purl/1769894 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsvd():\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(f: Callable, k: int, data: dict, *args):\n",
    "    \"\"\" \n",
    "    Benchmarks performance of an algorithm on the given datasets.\n",
    "\n",
    "    Inputs:\n",
    "    - f (Callable): the PCA algorithm\n",
    "        - should take in an argument for data and an argument for number of principal components\n",
    "    - k (int): the desired number of principal components\n",
    "    - data (dict): the datasets, where data[params] = dataset\n",
    "\n",
    "    Returns:\n",
    "    - dict of accuracy metrics by dataset\n",
    "    \"\"\"\n",
    "    accuracy_metrics = {}\n",
    "\n",
    "    for (params, dataset) in data.items():\n",
    "        # Calculate proportion of total variance for top k PCs\n",
    "        accuracy_key = (params, k)\n",
    "        pcs = f(dataset, k, *args)\n",
    "        \n",
    "        accuracy_metrics[accuracy_key] = utils.compute_prop_variance(pcs, dataset)\n",
    "\n",
    "    return accuracy_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_X(X: np.array):\n",
    "    \"\"\" \n",
    "    Returns a centered version of X so that each column has mean 0.\n",
    "\n",
    "    Input:\n",
    "    - X (2D numpy array): dataset\n",
    "\n",
    "    Returns:\n",
    "    - Xtilde, centered version of X\n",
    "    \"\"\"\n",
    "    return X - np.mean(X, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for k\n",
    "k_vals = [1, 2, 3, 5, 10, 20, 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_arsvd(X, k, dstar):\n",
    "    m, n = X.shape[0], X.shape[1]\n",
    "    transpose = False \n",
    "    # Check if transposing is necessary\n",
    "    if X.shape[0] < X.shape[1]:\n",
    "        X = X.T \n",
    "        transpose = True \n",
    "        VT, _, _ = rsvd(X, dstar)\n",
    "    else:\n",
    "        _, _, V = rsvd(X, dstar)\n",
    "\n",
    "    \n",
    "    # Compute top k pcs\n",
    "    Xtilde = center_X(X)\n",
    "\n",
    "    pcs = []\n",
    "\n",
    "    if transpose:\n",
    "        for i in range(min(dstar, k)):\n",
    "            pc = VT[:, i]\n",
    "            pcs.append(pc)\n",
    "    else:\n",
    "        for i in range(min(dstar, k)):\n",
    "            pc = V[i, :]\n",
    "            pcs.append(pc)\n",
    "    \n",
    "    return np.array(pcs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "diag requires an array of at least two dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m arsvd_benchmark \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_vals:\n\u001b[0;32m----> 5\u001b[0m     results \u001b[38;5;241m=\u001b[39m benchmark(pca_arsvd, k, G_simulated, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      6\u001b[0m     arsvd_benchmark\u001b[38;5;241m.\u001b[39mappend(results)\n",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(f, k, data, *args)\u001b[0m\n\u001b[1;32m     18\u001b[0m     accuracy_key \u001b[38;5;241m=\u001b[39m (params, k)\n\u001b[1;32m     19\u001b[0m     pcs \u001b[38;5;241m=\u001b[39m f(dataset, k, \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 21\u001b[0m     accuracy_metrics[accuracy_key] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcompute_prop_variance(pcs, dataset)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_metrics\n",
      "File \u001b[0;32m~/Desktop/Classes/math221/project/code/utils.py:126\u001b[0m, in \u001b[0;36mcompute_prop_variance\u001b[0;34m(pcs, data)\u001b[0m\n\u001b[1;32m    123\u001b[0m total_variance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtrace(np\u001b[38;5;241m.\u001b[39mcov(data, rowvar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Compute variance of data when projected onto pcs\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m projected_variance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtrace(np\u001b[38;5;241m.\u001b[39mcov(data \u001b[38;5;241m@\u001b[39m pcs, rowvar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m projected_variance\u001b[38;5;241m/\u001b[39mtotal_variance\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1774\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(a, offset, axis1, axis2, dtype, out)\u001b[0m\n\u001b[1;32m   1772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m asarray(a)\u001b[38;5;241m.\u001b[39mtrace(offset\u001b[38;5;241m=\u001b[39moffset, axis1\u001b[38;5;241m=\u001b[39maxis1, axis2\u001b[38;5;241m=\u001b[39maxis2, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m asanyarray(a)\u001b[38;5;241m.\u001b[39mtrace(offset\u001b[38;5;241m=\u001b[39moffset, axis1\u001b[38;5;241m=\u001b[39maxis1, axis2\u001b[38;5;241m=\u001b[39maxis2, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mValueError\u001b[0m: diag requires an array of at least two dimensions"
     ]
    }
   ],
   "source": [
    "# Benchmarking\n",
    "arsvd_benchmark = []\n",
    "\n",
    "for k in k_vals:\n",
    "    results = benchmark(pca_arsvd, k, G_simulated, 10)\n",
    "    arsvd_benchmark.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[((50, 10000, 0.0001), 5)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
